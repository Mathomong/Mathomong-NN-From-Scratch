# **Mathomong AI Club**

![mathomong](mathomong.png)

# Calculus in Neural Networks: A Beginner's Guide

---

## ğŸ“˜ What You Will Learn

By the end of this guide, youâ€™ll understand:

* Why neural networks need calculus
* What derivatives really mean (intuitively!)
* How gradients guide learning
* What backpropagation is and why it's powerful
* How everything fits together in training a neural network

---

# ğŸŒŸ Part 1: Why Calculus?

Neural networks have **parameters** (weights and biases).
Training means:

> **Finding the best values for these parameters.**

To do that, we ask:

> â€œIf I change this weight slightly, how will the error change?â€

This is exactly what **calculus** answers.

### âš¡ Calculus = The Mathematics of Change

Neural networks improve by *slowly adjusting parameters in the direction that reduces error*.

To know the best direction â†’ we need **derivatives**.
To know how big each adjustment should be â†’ we use **gradients**.

---

# ğŸŸ¦ Part 2: Derivatives â€” The Core Idea

### ğŸ”‘ What is a derivative (intuition)?

A derivative answers:

> **â€œIf I change input a tiny bit, how does the output change?â€**

Example:

```
y = xÂ²
dy/dx = 2x
```

Which means:

* If x = 3, then a tiny change in x causes y to change by about **6 times** that amount.

### Why neural networks need this

A neural network wants to know:

> â€œIf I increase/decrease weight W by a tiny amount, does loss go up or down?â€

Thatâ€™s a derivative.

---

# ğŸ§© Part 3: Loss Functions (Where Calculus Happens)

Neural networks donâ€™t know what correct weights are.
So we create a **loss function**, which measures *how wrong the network is*.

Example (mean squared error):

```
Loss = (prediction âˆ’ target)Â²
```

The goal is:

> Minimize loss by adjusting weights.

To do that, we need:

```
d(Loss)/d(weight)
```

---

# ğŸ“‰ Part 4: Gradient Descent â€” Learning Through Calculus

Gradient Descent is the algorithm that uses calculus to update weights:

```
new_weight = old_weight âˆ’ learning_rate Ã— gradient
```

### What is a gradient?

A gradient is:

* A **vector of all partial derivatives**
* It tells us the **direction of steepest increase**
* So we move **in the opposite direction** to minimize loss

Think of it like sliding down a hill to reach the lowest valley.

---

# ğŸ¯ Part 5: Partial Derivatives â€” Essential for Multi-Input Systems

A neuron receives many inputs:

```
z = W1x1 + W2x2 + â€¦ + Wnxn + b
```

The loss depends on *each weight separately*, so we compute:

```
âˆ‚Loss/âˆ‚W1
âˆ‚Loss/âˆ‚W2
...
âˆ‚Loss/âˆ‚Wn
```

These are partial derivatives â€” calculus for functions with many variables.

---

# ğŸ”„ Part 6: The Chain Rule â€” The Engine Behind Backpropagation

### Why the chain rule?

In a neural network:

```
input â†’ layer1 â†’ layer2 â†’ layer3 â†’ loss
```

Each layerâ€™s output depends on the previous layerâ€™s output.

To compute derivative at early layers, you must "chain" effects backward.

Chain Rule says:

> If A affects B, and B affects C, then
> A affects C by multiplying their derivatives.

Formally:

```
dC/dA = dC/dB Ã— dB/dA
```

In a neural network:

```
dLoss/dW = dLoss/dOutput Ã— dOutput/dZ Ã— dZ/dW
```

That's backpropagation.

---

# ğŸ”¥ Part 7: Backpropagation â€” The Brain of Training

Backpropagation applies the chain rule across layers to compute gradients efficiently.

### Steps:

1. **Forward Pass**

   * Compute predictions
   * Compute loss

2. **Backward Pass**

   * Compute gradients layer-by-layer using chain rule

3. **Update Weights**

   * Using gradient descent

Backpropagation gives exact derivatives for millions of parameters using simple repeated calculus rules.

---

# ğŸ§  Part 8: Activation Functions and Calculus

Activation functions introduce **nonlinearity**, but they must be differentiable for training.

Common ones:

### 1. **ReLU**

```
ReLU(x) = max(0, x)
d/dx = 0 (x<0), 1 (x>0)
```

### 2. **Sigmoid**

```
sigmoid(x) = 1 / (1+e^-x)
derivative = sigmoid(x)(1âˆ’sigmoid(x))
```

### 3. **Tanh**

```
derivative = 1 âˆ’ tanhÂ²(x)
```

The fact that all these have known derivatives makes training possible.

---

# ğŸ§® Part 9: Example â€” Calculus in One Neuron

Consider a simple neuron:

```
z = Wx + b
prediction = sigmoid(z)
loss = (prediction âˆ’ target)Â²
```

To train it:

We compute:

1. âˆ‚Loss/âˆ‚prediction
2. âˆ‚prediction/âˆ‚z
3. âˆ‚z/âˆ‚W and âˆ‚z/âˆ‚b

Using chain rule:

```
âˆ‚Loss/âˆ‚W = âˆ‚Loss/âˆ‚prediction Ã— âˆ‚prediction/âˆ‚z Ã— âˆ‚z/âˆ‚W
```

This is the logic for all neural networks â€” just repeated many times.

---

# ğŸŒŠ Part 10: Calculus Shapes the Learning Landscape

Think of the loss function as a mountain valley.
Training is the process of:

* Standing somewhere on the mountain (initial weights)
* Calculating the slope beneath your feet (gradient)
* Taking a step downhill
* Repeating until reaching a low point

**Calculus = Understanding the slope**
**Optimizers = Deciding how to move**
**Networks = Learning the landscape**

---

# ğŸ’¡ Key Takeaways

1. **Neural networks learn by minimizing error**
2. **Calculus tells us how changing weights affects error**
3. **Derivatives measure sensitivity (change in change)**
4. **Gradients show direction for learning**
5. **Chain rule lets information flow backward**
6. **Backpropagation = efficient gradient computation**
7. **Learning = adjusting millions of parameters using calculus**

---

# ğŸš€ Whatâ€™s Next?

To build deeper understanding:

* Watch 3Blue1Brownâ€™s *â€œBackpropagation Explainedâ€*
* Practice computing simple derivatives by hand
* Build a neural network from scratch in Python/Numpy
* Visualize gradient descent on simple 2D functions
* Join the **Mathomong AI Club** to grow with others!

---

*"In learning, you will teach, and in teaching, you will learn."* â€” Phil Collins

**Welcome to the Mathomong AI Club!**
